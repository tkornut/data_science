{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import string\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Tokenizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "# Demo with different tokenizers.\n",
    "# https://text-processing.com/demo/tokenize/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary using words from questions from both training.\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "\n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "\n",
    "# Dictionary word_to_ix maps each word in the vocab to a unique integer.\n",
    "word_to_ix = {}\n",
    "# Add special word <PAD> that we will use that during padding.\n",
    "# As a result, the \"real\" enumeration will start from 1.\n",
    "word_to_ix['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export mappings to file.\n",
    "def save_mappings_to_csv_file(folder, filename, word_to_ix, fieldnames = [\"word\", \"index\"], show = False):\n",
    "    \"\"\"\n",
    "    Saves mappings dictionary to a file.\n",
    "\n",
    "    :param filename: File with encodings (absolute path + filename).\n",
    "    :param word_to_ix: dictionary with word:index keys\n",
    "    \"\"\"\n",
    "    # Expand path.\n",
    "    folder = os.path.expanduser(folder)\n",
    "    # Make sure directory exists.\n",
    "    os.makedirs(os.path.dirname(folder +'/'), exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(folder, filename)\n",
    "\n",
    "    with open(file_path, mode='w+') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        # Create header.\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Write word-index pairs.\n",
    "        for (k,v) in word_to_ix.items():\n",
    "            if show:\n",
    "                print(\"{} : {}\".format(k,v))\n",
    "            writer.writerow({fieldnames[0]:k, fieldnames[1]: v})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_question_words_to_vocabulary(word_to_ix, questions):\n",
    "    \"\"\"\n",
    "    Processes questions one by one, dividing each into seperate words.\n",
    "    \"\"\"\n",
    "    for question in questions:\n",
    "        # Remove punctuation.\n",
    "        question = question.translate(table)\n",
    "        # Lowercase.\n",
    "        question = question.lower()\n",
    "        # Parse tokens.\n",
    "        for word in tokenizer.tokenize(question):\n",
    "            # If new token.\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                print(\"Adding '{}': {}\".format(word, len(word_to_ix)-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tomaszkornuta/data/CLEVR_v1.0\n"
     ]
    }
   ],
   "source": [
    "# Set folders.\n",
    "data_folder = os.path.expanduser('~/data/CLEVR_v1.0')\n",
    "print(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'questions'])\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_file = os.path.join(data_folder, \"questions\", 'CLEVR_train_questions.json')\n",
    "with open(train_file) as f:\n",
    "    train_dataset = json.load(f)\n",
    "print(train_dataset.keys())\n",
    "train_dataset = train_dataset[\"questions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699989\n",
      "dict_keys(['image_index', 'program', 'question_index', 'image_filename', 'question_family_index', 'split', 'answer', 'question'])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(train_dataset[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_index': 0, 'program': [{'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [0], 'function': 'filter_size', 'value_inputs': ['large']}, {'inputs': [1], 'function': 'filter_color', 'value_inputs': ['green']}, {'inputs': [2], 'function': 'count', 'value_inputs': []}, {'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [4], 'function': 'filter_size', 'value_inputs': ['large']}, {'inputs': [5], 'function': 'filter_color', 'value_inputs': ['purple']}, {'inputs': [6], 'function': 'filter_material', 'value_inputs': ['metal']}, {'inputs': [7], 'function': 'filter_shape', 'value_inputs': ['cube']}, {'inputs': [8], 'function': 'count', 'value_inputs': []}, {'inputs': [3, 9], 'function': 'greater_than', 'value_inputs': []}], 'question_index': 0, 'image_filename': 'CLEVR_train_000000.png', 'question_family_index': 2, 'split': 'train', 'answer': 'yes', 'question': 'Are there more big green things than large purple shiny cubes?'}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 'are': 1\n",
      "Adding 'there': 2\n",
      "Adding 'more': 3\n",
      "Adding 'big': 4\n",
      "Adding 'green': 5\n",
      "Adding 'things': 6\n",
      "Adding 'than': 7\n",
      "Adding 'large': 8\n",
      "Adding 'purple': 9\n",
      "Adding 'shiny': 10\n",
      "Adding 'cubes': 11\n",
      "Adding 'how': 12\n",
      "Adding 'many': 13\n",
      "Adding 'other': 14\n",
      "Adding 'of': 15\n",
      "Adding 'the': 16\n",
      "Adding 'same': 17\n",
      "Adding 'shape': 18\n",
      "Adding 'as': 19\n",
      "Adding 'tiny': 20\n",
      "Adding 'cyan': 21\n",
      "Adding 'matte': 22\n",
      "Adding 'object': 23\n",
      "Adding 'is': 24\n",
      "Adding 'color': 25\n",
      "Adding 'sphere': 26\n",
      "Adding 'cube': 27\n",
      "Adding 'what': 28\n",
      "Adding 'material': 29\n",
      "Adding 'that': 30\n",
      "Adding 'right': 31\n",
      "Adding 'brown': 32\n",
      "Adding 'cylinder': 33\n",
      "Adding 'and': 34\n",
      "Adding 'left': 35\n",
      "Adding 'gray': 36\n",
      "Adding 'on': 37\n",
      "Adding 'side': 38\n",
      "Adding 'small': 39\n",
      "Adding 'rubber': 40\n",
      "Adding 'behind': 41\n",
      "Adding 'thing': 42\n",
      "Adding 'to': 43\n",
      "Adding 'metallic': 44\n",
      "Adding 'size': 45\n",
      "Adding 'any': 46\n",
      "Adding 'have': 47\n",
      "Adding 'block': 48\n",
      "Adding 'blue': 49\n",
      "Adding 'yellow': 50\n",
      "Adding 'a': 51\n",
      "Adding 'it': 52\n",
      "Adding 'ball': 53\n",
      "Adding 'its': 54\n",
      "Adding 'in': 55\n",
      "Adding 'front': 56\n",
      "Adding 'does': 57\n",
      "Adding 'number': 58\n",
      "Adding 'red': 59\n",
      "Adding 'spheres': 60\n",
      "Adding 'made': 61\n",
      "Adding 'metal': 62\n",
      "Adding 'cylinders': 63\n",
      "Adding 'both': 64\n",
      "Adding 'balls': 65\n",
      "Adding 'or': 66\n",
      "Adding 'blocks': 67\n",
      "Adding 'objects': 68\n",
      "Adding 'visible': 69\n",
      "Adding 'another': 70\n",
      "Adding 'has': 71\n",
      "Adding 'greater': 72\n",
      "Adding 'fewer': 73\n",
      "Adding 'less': 74\n",
      "Adding 'either': 75\n",
      "Adding 'anything': 76\n",
      "Adding 'else': 77\n",
      "Adding 'do': 78\n",
      "Adding 'an': 79\n",
      "Adding 'equal': 80\n"
     ]
    }
   ],
   "source": [
    "train_questions = [item[\"question\"] for item in train_dataset]\n",
    "add_question_words_to_vocabulary(word_to_ix, train_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'questions'])\n"
     ]
    }
   ],
   "source": [
    "valid_file = os.path.join(data_folder, \"questions\", 'CLEVR_val_questions.json')\n",
    "with open(valid_file) as f:\n",
    "    valid_dataset = json.load(f)\n",
    "print(valid_dataset.keys())\n",
    "valid_dataset = valid_dataset[\"questions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149991\n",
      "dict_keys(['image_index', 'program', 'question_index', 'image_filename', 'question_family_index', 'split', 'answer', 'question'])\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_dataset))\n",
    "print(valid_dataset[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_index': 0, 'program': [{'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [0], 'function': 'filter_size', 'value_inputs': ['large']}, {'inputs': [1], 'function': 'filter_material', 'value_inputs': ['metal']}, {'inputs': [2], 'function': 'unique', 'value_inputs': []}, {'inputs': [3], 'function': 'same_shape', 'value_inputs': []}, {'inputs': [4], 'function': 'exist', 'value_inputs': []}], 'question_index': 0, 'image_filename': 'CLEVR_val_000000.png', 'question_family_index': 39, 'split': 'val', 'answer': 'no', 'question': 'Are there any other things that are the same shape as the big metallic object?'}\n"
     ]
    }
   ],
   "source": [
    "print(valid_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_questions = [item[\"question\"] for item in valid_dataset]\n",
    "add_question_words_to_vocabulary(word_to_ix, valid_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'questions'])\n",
      "{'split': 'test', 'license': 'Creative Commons Attribution (CC BY 4.0)', 'version': '1.0', 'date': '2/14/2017'}\n",
      "{'image_index': 0, 'split': 'test', 'image_filename': 'CLEVR_test_000000.png', 'question_index': 0, 'question': 'Is there anything else that is the same shape as the small brown matte object?'}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_file = os.path.join(data_folder, \"questions\", 'CLEVR_test_questions.json')\n",
    "with open(test_file) as f:\n",
    "    test_dataset = json.load(f)\n",
    "print(test_dataset.keys())\n",
    "print(test_dataset[\"info\"])\n",
    "print(test_dataset[\"questions\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [item[\"question\"] for item in test_dataset[\"questions\"]]\n",
    "add_question_words_to_vocabulary(word_to_ix, test_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to:  questions.all.word.mappings.lowercase.csv\n",
      "<PAD> : 0\n",
      "are : 1\n",
      "there : 2\n",
      "more : 3\n",
      "big : 4\n",
      "green : 5\n",
      "things : 6\n",
      "than : 7\n",
      "large : 8\n",
      "purple : 9\n",
      "shiny : 10\n",
      "cubes : 11\n",
      "how : 12\n",
      "many : 13\n",
      "other : 14\n",
      "of : 15\n",
      "the : 16\n",
      "same : 17\n",
      "shape : 18\n",
      "as : 19\n",
      "tiny : 20\n",
      "cyan : 21\n",
      "matte : 22\n",
      "object : 23\n",
      "is : 24\n",
      "color : 25\n",
      "sphere : 26\n",
      "cube : 27\n",
      "what : 28\n",
      "material : 29\n",
      "that : 30\n",
      "right : 31\n",
      "brown : 32\n",
      "cylinder : 33\n",
      "and : 34\n",
      "left : 35\n",
      "gray : 36\n",
      "on : 37\n",
      "side : 38\n",
      "small : 39\n",
      "rubber : 40\n",
      "behind : 41\n",
      "thing : 42\n",
      "to : 43\n",
      "metallic : 44\n",
      "size : 45\n",
      "any : 46\n",
      "have : 47\n",
      "block : 48\n",
      "blue : 49\n",
      "yellow : 50\n",
      "a : 51\n",
      "it : 52\n",
      "ball : 53\n",
      "its : 54\n",
      "in : 55\n",
      "front : 56\n",
      "does : 57\n",
      "number : 58\n",
      "red : 59\n",
      "spheres : 60\n",
      "made : 61\n",
      "metal : 62\n",
      "cylinders : 63\n",
      "both : 64\n",
      "balls : 65\n",
      "or : 66\n",
      "blocks : 67\n",
      "objects : 68\n",
      "visible : 69\n",
      "another : 70\n",
      "has : 71\n",
      "greater : 72\n",
      "fewer : 73\n",
      "less : 74\n",
      "either : 75\n",
      "anything : 76\n",
      "else : 77\n",
      "do : 78\n",
      "an : 79\n",
      "equal : 80\n"
     ]
    }
   ],
   "source": [
    "# Generate the name of file.\n",
    "name = 'questions.all.word.mappings.lowercase.csv'\n",
    "\n",
    "print(\"Saving to: \",name)\n",
    "# Save to both \"destinations.\"\n",
    "save_mappings_to_csv_file(data_folder, name, word_to_ix)\n",
    "save_mappings_to_csv_file('.', name, word_to_ix, show = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
